# -*- coding: utf-8 -*-
"""ProyectoFinal_Entrega3_FacundoFederico.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d23PQhxj_R9nBcDNxBfafIF8ju0e7EjO

# Research on Metallica's songs

# Abstract

Metallica is a 43-years-old thrash-metal band with multiple awards under their belt.

Since added to Spotify, they have garnered over 11.5 billion streams, with an average of more than 5.8 million streams each day.

After the success of their last album, they are already planning a new release, and they contacted our team with the intention of getting some insight from their Spotify tracks’ data.

### Objectives
- Define with track attributes Metallica's ‘identity’.
- Find, if any, ‘identity’ groups in order to ensure variety in the new album.
- Find out if remastered songs are more popular that original ones, since they are interested in including some old songs to their album.
- Define if the length of a song has any impact on its popularity.
- Train a model to test if the new songs will be popular.

### Considerations
We are not considering records of the live version of a song, since the band wants to release a studio-recorded album.

### Code dependancies
"""

!pip install spotipy
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import spotipy
from statistics import mean
from google.colab import userdata
from sklearn.cluster import DBSCAN, KMeans
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, f1_score, precision_score
from sklearn.model_selection import StratifiedKFold, train_test_split
from spotipy.oauth2 import SpotifyClientCredentials
from sklearn.preprocessing import StandardScaler
from typing import Callable

"""# Data Source

We are getting our data from Spotify's API using Spotipy
"""

# Use our credentials to access a Spotipy instance
client_id = userdata.get('client_id')
client_secret = userdata.get('client_secret')
client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)
sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)

# Get Metallica's id
name = ['Metallica']
result = sp.search(name)
artist_uri = result['tracks']['items'][1]['artists'][0]['uri']

# Get albums' ids
albums = sp.artist_albums(artist_id=artist_uri, album_type='album')['items']
album_uris = list(map(lambda x: x['uri'], albums))

# Get tracks' ids
track_uris = []
for album_uri in album_uris:
  album_track_uris = map(lambda x : x['id'], sp.album_tracks(album_id=album_uri)['items'])
  track_uris.extend(album_track_uris)

track_uris = list(dict.fromkeys(track_uris))

# Get track data
tracks = []
audio_features = []
for i in range(0, len(track_uris), 50):
  tracks.extend(sp.tracks(tracks=track_uris[i:i + 50])['tracks'])

for i in range(0, len(track_uris), 100):
  audio_features.extend(sp.audio_features(tracks=track_uris[i:i + 100]))

# Get dataframe
df_tracks = pd.json_normalize(data=tracks, max_level=0)
df_tracks = df_tracks[['name', 'duration_ms', 'popularity']].set_index(df_tracks['id'])
df_features = pd.json_normalize(data=audio_features, max_level=0)
df_features = df_features[['danceability', 'energy', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']].set_index(df_features['id'])
df = df_tracks.join(df_features)

"""# Exploratory Data Analysis

First, we want to know what kind of data we have.
"""

df.info()

df.isna().sum()

df.describe()

"""Based on Spotify's API, we have the following definitions:
- **id**: Spotify's track id as a string value.
- **name**: the name of the song as a string value.
- **duration_ms**: the duration of the song in milliseconds, as an integer.
- **popularity**: the popularity of the song, as a 0 to 100 integer value that takes into account both the number of plays and how recent these are.
- **danceability**: how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity, as a float value from 0.0 to 1.0.
- **energy**: perceptual measure of intensity and activity, as a float value from 0.0 to 1.0.
- **loudness**: average loudness of a track in decibels (dB), as a float value.
- **mode**: modality (major or minor) of a track, as an integer that can be either 0 (minor) or 1 (major).
- **speechiness**: presence of spoken words in a track, as a float value from 0.0 to 1.0.
- **acousticness**: confidence of whether the track is acoustic (presence of sound created by acoustic means such as instruments as opposed to electronic means), as a float value from 0.0 to 1.0.
- **instrumentalness**: whether a track contains no vocals, as a float value from 0.0 to 1.0.
- **liveness**: presence of an audience in the recording, as a float value from 0.0 to 1.0.
- **valence**: musical positiveness conveyed by a track, as a float value from 0.0 to 1.0.
- **tempo**: estimated average tempo of a track in beats per minute (BPM), as a float value.
- **time_signature**: notational convention to specify how many beats are in each bar (or measure), as an integer that ranges from 3 to 7, indicating time signatures of "3/4", to "7/4".
"""

f, axs = plt.subplots(2, 3, figsize=(12, 6))

sns.histplot(data=df, x='duration_ms', kde=True, ax=axs[0,0])
sns.histplot(data=df, x='popularity', kde=True, ax=axs[0,1])
sns.histplot(data=df, x='loudness', kde=True, ax=axs[0,2])
sns.countplot(data=df, x='mode', hue='mode', formatter=lambda x: 'minor' if x == 0 else 'major', legend=False, ax=axs[1,0])
sns.histplot(data=df, x='tempo', kde=True, ax=axs[1,1])
sns.countplot(data=df, x='time_signature', hue='time_signature', legend=False, ax=axs[1,2])

f.tight_layout()

f, ax = plt.subplots(figsize=(11, 6))

sns.violinplot(data=df[['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence']], bw_adjust=.5, cut=1, linewidth=1, palette="Set3")

ax.set(ylim=(-0.1, 1.1))
sns.despine(left=True, bottom=True)

"""## First impressions
So far we can see that the API returned no null values.

**duration_ms** ranges from 21927 to 1168906ms. Most tracks' duration round 400000ms, with some outliers around the 1100000ms. Some of the shorter tracks are suspiciously short for a song, so we should make sure of removing any track that might not be considered one (for example: album intros).

**time_signature** mode is 4, which fits the industry standard of "4/4" signatures. It appears to be one or more tracks with a signature of 1, which is extremely rare for music, so that outliers must be checked out.

There seems to be outliers in energy, speechiness, and acousticness.
"""

df[['name', 'duration_ms']].sort_values(by='duration_ms', inplace=False).head(5)

"""Apparently we have a number of tracks that contain individual guitar riffs. We will remove these since they are not songs themselves."""

df = df.loc[df['name'].str.upper().str.contains('RIFF TAPES') == False]
df[['name', 'duration_ms']].sort_values(by='duration_ms', inplace=False).head(5)

"""We now see that we also have "in progress" pieces and, as expected, album intros. We are removing both."""

df = df.loc[df['name'].str.upper().str.contains('IN PROGRESS') == False]
df = df.loc[df['name'].str.upper().str.contains('INTRO') == False]
df[['name', 'duration_ms']].sort_values(by='duration_ms', inplace=False).head(5)

f, axs = plt.subplots(2, 3, figsize=(12, 6))

sns.histplot(data=df, x='duration_ms', kde=True, ax=axs[0,0])
sns.histplot(data=df, x='popularity', kde=True, ax=axs[0,1])
sns.histplot(data=df, x='loudness', kde=True, ax=axs[0,2])
sns.countplot(data=df, x='mode', hue='mode', formatter=lambda x: 'minor' if x == 0 else 'major', legend=False, ax=axs[1,0])
sns.histplot(data=df, x='tempo', kde=True, ax=axs[1,1])
sns.countplot(data=df, x='time_signature', hue='time_signature', legend=False, ax=axs[1,2])

f.tight_layout()

"""The outliers that had a time signature of 1 have already been excluded."""

f, ax = plt.subplots(figsize=(11, 6))

sns.violinplot(data=df[['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence']], bw_adjust=.5, cut=1, linewidth=1, palette="Set3")

ax.set(ylim=(-0.1, 1.1))
sns.despine(left=True, bottom=True)

"""We still have some outliers that need to be investigated"""

df.sort_values(by='energy', inplace=False).head(5)

df.sort_values(by='acousticness', ascending=False, inplace=False).head(5)

df.sort_values(by='instrumentalness', ascending=False, inplace=False).head(5)

"""Outliers appear to be valid tracks.

# Data engineering

First, we are going to add a new column that represents whether the song is original, a remastered version or a live version
"""

def song_format(song):
  if '(REMASTERED)' in song['name'].upper():
    return 1
  if '- LIVE' in song['name'].upper():
    return 2
  return 0

df['format'] = df.apply(song_format, axis=1)

"""Now, we are going to remove some columns that we won't use.
- Name: the name of a song does not have a value in this study.
- Time_signature: it is an extremely unbalanced group, and any insight we get from it will be biased.

We will also sellect only the original and remastered tracks, since the band's objective is to release a studio-recorded album.
"""

df.drop(['name', 'time_signature'], axis=1, inplace=True)

df = df[df['format'] != 2]

"""# Data analysis"""

df['is_popular'] = df['popularity'] > df['popularity'].quantile(.75)
df_melted = df.melt(id_vars=['is_popular'], value_vars=['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence'])

f, ax = plt.subplots(figsize=(11, 6))
sns.violinplot(data=df_melted, x='variable', y='value', inner="quart", fill=False, split=True, hue='is_popular', density_norm='width', palette='flare')
ax.set(ylim=(0.0, 1.0))
plt.grid()
sns.despine()

del df_melted

f, axs = plt.subplots(2, 2, figsize=(11, 6))

df['duration_seconds'] = df['duration_ms'].apply(lambda x: x/1000)

sns.histplot(data=df, x='duration_seconds', ax=axs[0,0], hue='is_popular', linewidth=.5, palette="flare", kde=True)
sns.histplot(data=df, x='loudness', ax=axs[0,1], hue='is_popular', linewidth=.5, palette="flare", kde=True)
sns.countplot(data=df, x='mode', formatter=lambda x: 'Minor' if x == 0 else 'Major', legend=True, ax=axs[1,0], hue='is_popular', palette="flare")
sns.histplot(data=df, x='tempo', ax=axs[1,1], hue='is_popular', linewidth=.5, palette="flare", kde=True)

df.drop(columns='duration_seconds')
f.tight_layout()

sns.despine()

"""### Group finding
We will try to find identity groups between parameters that have a great influence in popularity, so that the band can have variety in their new tracks.
"""

fig, ax = plt.subplots(figsize=(10,10))
sns.heatmap(df.corr(),
            xticklabels = df.columns.values,
            yticklabels = df.columns.values,
            annot = True,
            ax = ax);

"""We can see a significant correlation coefficient between 'popularity' and:
- danceability
- speechiness
- liveness
- valence

Since 'format' was added as a way to identify the format of the song and is not inherent to the track, we are not taking it into account.
"""

sns.pairplot(df[['danceability', 'speechiness', 'liveness', 'valence', 'is_popular']], kind='kde', hue='is_popular', palette='flare')

"""We can see that liveness has a binormal distribution. The first bell has the same distribution as the popular group. On the other hand, the second bell barely has popular members, so it will not be taken into account.

We will train a k-means model with the other 3 attributes to define separated groups of songs that allow the band to have some variety within successful tracks.
"""

kmeans = KMeans(n_clusters=2, random_state=0, n_init="auto").fit(df[['danceability', 'valence', 'speechiness']])

df['group'] = kmeans.labels_
cluster_centers = kmeans.cluster_centers_

f, axs = plt.subplots(3, 2, figsize=(10, 10))

sns.kdeplot(data=df,x="danceability", y="speechiness", hue="is_popular",palette='flare',ax=axs[0,0])
sns.scatterplot(data=df,x="danceability", y="speechiness", hue="group",palette='crest',ax=axs[0,1])
for center in cluster_centers:
  axs[0,1].scatter(x=center[0], y=center[2], color='k')

sns.kdeplot(data=df,x="danceability", y="valence", hue="is_popular",palette='flare',ax=axs[1,0])
sns.scatterplot(data=df,x="danceability", y="valence", hue="group",palette='crest',ax=axs[1,1])
for center in cluster_centers:
  axs[1,1].scatter(x=center[0], y=center[1], color='k')

sns.kdeplot(data=df,x="speechiness", y="valence", hue="is_popular",palette='flare',ax=axs[2,0])
sns.scatterplot(data=df,x="speechiness", y="valence", hue="group",palette='crest',ax=axs[2,1])
for center in cluster_centers:
  axs[2,1].scatter(x=center[2], y=center[1], color='k')

f.tight_layout()
sns.despine()

"""We can see that valence-danceability perspective shows a clear separation between the 2 groups, so we are going to define them with this variables. We will describe the clusters with the centers:
- danceability: 0.47, valence: 0.52
- danceability: 0.33, valence: 0.27
"""

sns.countplot(data=df, x='format', formatter=lambda x: 'Original' if x == 0 else 'Remaster', legend=True, hue='is_popular', palette="flare")

sns.scatterplot(data=df, x='duration_seconds', y='popularity', linewidth=.5, palette="flare", hue='popularity')

"""# Insights

### Metallica's identity
After analysing the obtained tracks' parameters, we can provide Metallica with the following guidelines for their new album's tracks:
- Energy:       			  ~0.95
- Speechiness:		      ~0.05
- Acousticness:		      ~0.00
- Instrumentalness:		  ~0.00
- Liveness:			        ~0.10
- Danceability-Valence:	~(0.47, 0.52), ~(0.33, 0.27)
- Duration:			        ~350 seconds
- Loudness:			        Between -10.0 and -6.0dB, and ~-4.0dB
- Tempo:				        Between 90 and 150BPM, and ~180BPM
- Mode: 				        Mostly minor, but also some major

### Original vs remastered tracks
By comparing the popularity of both original and remastered tracks we can see that, proportionally, remastered tracks have a higher rate of success.
The band should not be afraid of adding some remastered tracks to their album.

### Impact of duration in popularity
By contrasting the duration of tracks and their popularity we can clearly see no correlation between those variables.

# Model training

### Component selection
We will create a logistic regression model that predicts if a song will be popular or not, so that the band can test new songs before releasing them.

First, we need to remove some parameters that will not have an impact in this study.
Based on the previous correlation study, we will only keep:
- Danceability
- Loudness
- Speechiness
- Liveness
- Valence
"""

df.drop('duration_ms', axis=1, inplace=True)
df.drop('popularity', axis=1, inplace=True)
df.drop('energy', axis=1, inplace=True)
df.drop('mode', axis=1, inplace=True)
df.drop('acousticness', axis=1, inplace=True)
df.drop('instrumentalness', axis=1, inplace=True)
df.drop('tempo', axis=1, inplace=True)
df.drop('format', axis=1, inplace=True)
df.drop('duration_seconds', axis=1, inplace=True)
df.drop('group', axis=1, inplace=True)

df.head(5)

"""### Hypertunning
We will use hypertunning with stratified cross-validation to define the parameters we are going to train our model with.
"""

X, y = df.drop('is_popular', axis=1), df['is_popular']

# Scale
sc = StandardScaler()
X = sc.fit_transform(X)

def HyperparameterResult(n_components: int, class_weight: str, desicion_func: Callable):
  pca = PCA(n_components=n_components)
  X_pca = pca.fit_transform(X)

  clf = LogisticRegression(max_iter=1000, class_weight=class_weight)
  skf = StratifiedKFold(n_splits=5)

  score_array = [0]*5
  for i, (train_index, test_index) in enumerate(skf.split(X_pca, y)):
    clf.fit(X_pca[train_index], y[train_index])
    y_predict = clf.predict(X_pca[test_index])

    score_array[i] = precision_score(y[test_index], y_predict, zero_division=0)

  final_score = desicion_func(score_array)
  return final_score

"""Here we declared a function that takes the number of PCA components as a parameter and uses it to apply PCA to our samples, train a LogisticRegression model and use StratifiedKFold to evaluate it with a provided approach."""

pca_components = np.array([*range(1, 6)])
class_weight = np.array([None, 'balanced'])
desicion_func = mean
combinations = np.array([[HyperparameterResult(i, j, desicion_func) for j in class_weight] for i in pca_components])

grid = pd.DataFrame(
    data= combinations,
    index= pca_components,
    columns= class_weight)

sns.heatmap(grid, annot=True, linewidths=.5, xticklabels=['none', 'balanced'])

"""We can see that the best resut is obtained by training a non-weighted Logistic Regression and using only 1 component.

### Component reduction
Using the results of the hypertunning process, we will use PCA to reduce the 5 components into 1.
"""

pca = PCA(n_components=1)
sc = StandardScaler()
X = sc.fit_transform(df.drop('is_popular', axis=1))

# split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, df['is_popular'], test_size=0.3, random_state=3)
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)

"""### Logistic regression model training
We will use the transformed components to train and test a logistic regression model
"""

clf = LogisticRegression(max_iter=1000, class_weight=None)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

conf_m = confusion_matrix(y_test, y_pred)

print("Precision score:", precision_score(y_test, y_pred))
print(conf_m)

"""This precision, although acceptable, has a lot of room for improvement.

# Conclusion

Thanks to this project we can provide the band not only with guidelines for creating new songs, but also a tool they can use to check, with some degree of precision, if a new song will be popular or not.
"""